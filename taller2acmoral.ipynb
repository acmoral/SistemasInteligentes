{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "taller2acmoral.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acmoral/SistemasInteligentes/blob/main/taller2acmoral.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viE_xL9_VXxm"
      },
      "source": [
        "# Quiz 2\n",
        "\n",
        "## Introducción a los Sistemas Inteligentes 2020-1\n",
        "\n",
        "-------------------\n",
        "\n",
        "Aima ha notado tu presencia en la Unión Nacional de Algoritmos de Localización (UNAL). Siendo esta una institución de alto prestigio ha decidido ponerte a prueba. Para ello te ha asignado a trabajar en un challenge de Kaggle.\n",
        "\n",
        "El hundimiento del RMS Titanic es uno de los naufragios más famosos de la historia. El 15 de abril de 1912, el Titanic se hundió después de estrellarse con un iceberg, matando 1502 de 2224 pasageros y tripulación. Este evento sacudió toda la comunidad internacional e implico mejoras en las medidas de seguridad para Barcos.\n",
        "\n",
        "Una de las razones de tantas perdidas humanas fue la falta de botes salvavidas. Aunque la sobrevivencia de una persona se regia un poco por la suerte algunos grupos de personas tenian mayor chance de sobrevivir que otros, como mujeres, niños y miembros de la clase alta.\n",
        "\n",
        "En este reto se le solicita que complete el análisis sobre que tipo de personas eran más propensas a sobrevivir. En particular se le solicita que aplique las herramientas del machine learning para predecir que pasajeros del RMS Titanic sobrevivieron.\n",
        "[Ver más](https://www.kaggle.com/c/titanic/overview)\n",
        "\n",
        "\n",
        "**Para descargar el archivo de datos en el siguiente link: [titanic.csv](https://drive.google.com/file/d/1KZD9Ic2Gmd39yLlFlHSSs6lgDqyWuPCW/view?usp=sharing)**\n",
        "\n",
        "----------------------------------\n",
        "La siguiente tabla muestra información sobre (algunas) variables presentes en el dataset\n",
        "\n",
        "Data Dictionary\n",
        "```\n",
        "Variable\tDefinition\tKey\n",
        "survived \tSurvival \t0 = No, 1 = Yes\n",
        "pclass\t\tTicket class \t1 = 1st, 2 = 2nd, 3 = 3rd\n",
        "sex \t\tSex \t\n",
        "Age \t\tAge in years \t\n",
        "sibsp \t\t# of siblings / spouses aboard the Titanic \t\n",
        "parch \t\t# of parents / children aboard the Titanic \t\n",
        "ticket \t\tTicket number \t\n",
        "fare \t\tPassenger fare \t\n",
        "cabin \t\tCabin number \t\n",
        "embarked \tPort of Embarkation \tC = Cherbourg, Q = Queenstown, S = Southampton\n",
        "```\n",
        "\n",
        "#### Variable Notes\n",
        "\n",
        "- **pclass**: A proxy for socio-economic status (SES)\n",
        "    1st = Upper\n",
        "    2nd = Middle\n",
        "    3rd = Lower\n",
        "\n",
        "- **age**: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n",
        "\n",
        "- **sibsp**: The dataset defines family relations in this way...\n",
        "    Sibling = brother, sister, stepbrother, stepsister\n",
        "    Spouse = husband, wife (mistresses and fiancés were ignored)\n",
        "\n",
        "- **parch**: The dataset defines family relations in this way...\n",
        "    Parent = mother, father\n",
        "    Child = daughter, son, stepdaughter, stepson\n",
        "\n",
        "    Some children travelled only with a nanny, therefore parch=0 for them.\n",
        "\n",
        "-------------------\n",
        "\n",
        "#### Notas adicionales:\n",
        "\n",
        "Sus modelos seran evaluados usando la métrica accuracy. No modifique la firma de las funciones (nombre y parametros)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WztzmQqRkcZt"
      },
      "source": [
        "# 1 Procesamiento y Exploración de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N92YrUGZoQEi"
      },
      "source": [
        "## 1.1 Cargue los datos\n",
        "* Algunas columnas tienen valores null, este es un reto común con el que se encontrar. Más adelante nos ocuparemos de esto. \n",
        "* Extraiga las features y el target del dataframe en dos variables. X, y.\n",
        "* Antes de ejecutar el código en la siguiente celda cargue el archivo `titanic.csv` en la raiz del sistema de archivos del ambiente de ejecución usando la opción correspondiente en el menú lateral."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QF4X0wldV3Ae"
      },
      "source": [
        "import sklearn\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Path donde se encuentra el archivo de datos.\n",
        "path = 'titanic.csv'\n",
        "df = pd.read_csv(path, index_col='PassengerId')\n",
        "\n",
        "X, y = df.drop(axis=1,columns=['Survived']), df.Survived"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcOchePkYTyS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "98176dcf-bba2-4772-dffd-9a749f754672"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 891 entries, 1 to 891\n",
            "Data columns (total 11 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Survived  891 non-null    int64  \n",
            " 1   Pclass    891 non-null    int64  \n",
            " 2   Name      891 non-null    object \n",
            " 3   Sex       891 non-null    object \n",
            " 4   Age       714 non-null    float64\n",
            " 5   SibSp     891 non-null    int64  \n",
            " 6   Parch     891 non-null    int64  \n",
            " 7   Ticket    891 non-null    object \n",
            " 8   Fare      891 non-null    float64\n",
            " 9   Cabin     204 non-null    object \n",
            " 10  Embarked  889 non-null    object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 83.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSo4d6E7tQqH"
      },
      "source": [
        "## 1.2 Extraiga las variables númericas que no tengan datos faltantes del dataset\n",
        "Debe determinar que variables columnas son de tipo numérico y no tienen datos faltantes. Para hacer esto use el atributo `dtypes` de los objetos de tipo `DataFrame` y el método `count()`.\n",
        "\n",
        "Implemente la función `extract_numerial` para obtener estos features del Dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wGKKroftQqU"
      },
      "source": [
        "def extract_features(X, features):\n",
        "    '''\n",
        "    X: dataframe como se define en 1.1\n",
        "    features: lista de features a ser extraidas\n",
        "    returns: X derivado con únicamente las columnas en features\n",
        "    '''\n",
        "    return X[features]\n",
        "\n",
        "def extract_numerical(X):\n",
        "    '''\n",
        "    X: dataframe como se define en 1.1\n",
        "    returns: dataframe derivado que puede ser usado para entrenar un modelo (sin variables categoricas )\n",
        "    '''\n",
        "    give=pd.DataFrame()\n",
        "    for features in X.keys():\n",
        "     s= extract_features(X,features)\n",
        "     if s.dtype !='O':    \n",
        "       s=s.fillna(s.mean())\n",
        "       s[s == -np.inf] =s.mean()\n",
        "       s[s == np.inf] =s.mean()\n",
        "       give[features]=s\n",
        "    # YOUR CODE GOES HERE\n",
        "    return give"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2tMdM9HY3I-"
      },
      "source": [
        "## 1.3 Entrene modelos de regresion logística y naïve bayes sobre los variables númericas\n",
        "\n",
        "Para este punto debe implementar dos funciones:\n",
        "- `train_logit`: para entrenar modelos de _Regresión Logística_. Esta función debe retornar un modelo ya entrenado de regresión logística siendo de la clase `LogisticRegression` de sklearn.\n",
        "    El modelo logístico debe superar 0.68 de presición.\n",
        "\n",
        "\n",
        "- `train_bayes`: para entrenar modelos de tipo _Naïve Bayes_. Esta función debe retornar un modelo ya entrenado de Naïve Bayes siendo de la clase `GaussianNB` de sklearn.\n",
        "    Este modelo debe superar 0.67 de presición.\n",
        "    \n",
        "**Peso del punto: 2.0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bF9LjdMBZ6en"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = LogisticRegression()\n",
        "classifier2 = GaussianNB()\n",
        "def train_logit(X, y):\n",
        "    '''\n",
        "    X: dataframe derivado de df como se define en 1.1\n",
        "    y: target como se define en 1.1\n",
        "    returns (LogisticRegression): modelo entrenado con los datos X y y\n",
        "    '''\n",
        "    # YOUR CODE GOES HERE\n",
        "    classifier.fit(X, y)\n",
        "    return classifier.fit(X,y)\n",
        "\n",
        "def train_bayes(X, y):\n",
        "    '''\n",
        "    X: dataframe derivado de df como se define en 1.1\n",
        "    y: target como se define en 1.1\n",
        "    returns (GaussianNB): modelo entrenado con los datos X y y\n",
        "    '''\n",
        "    # YOUR CODE GOES HERE\n",
        "    return classifier2.fit(X, y)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wT7I4lHYTyi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4464ed4a-17ba-490e-9893-58c25146c281"
      },
      "source": [
        "# Cell for testing.\n",
        "X_numerical = extract_numerical(X)\n",
        "logit = train_logit(X_numerical, y)\n",
        "bayes = train_bayes(X_numerical, y)\n",
        "\n",
        "print(logit.score(X_numerical, y))\n",
        "print(bayes.score(X_numerical, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7048260381593715\n",
            "0.6868686868686869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4ppH_x8dcmd"
      },
      "source": [
        "## 1.4 Entrene los modelos con los datos procesados y la feature 'Sex' con label encoding\n",
        "### 1.4.1 Haga label-encoding de la feature 'Sex'\n",
        "\n",
        "Label encoding consiste en asignar un label a cada grupo de datos, en este caso 'female' obtiene el label 1 y 'male' el label 0, o al revés. Lo importante es que los labels sean valores númericos.\n",
        "\n",
        "* Puede hacer un `for`\n",
        "* Puede usar `.map()` de Pandas sobre `X['Sex']`\n",
        "* Puede usar `sklearn.preprocessing.LabelEncoder`\n",
        "\n",
        "Cree un DataFrame que contenga las característica numéricas del punto 1.2 y que además tenga una columna correspondiente a la característica 'Sex' con label encoding.\n",
        "Para esto, implemente la función `process_data`.\n",
        "\n",
        "**Peso del punto: 1.0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jU1epCJrXCNk"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "def process_data(X):\n",
        "    '''\n",
        "    X : dataframe como se define en 1.1\n",
        "    returns (Dataframe): dataframe derivado de X con columnas númericas incluyendo 'Sex' con label encoding\n",
        "    '''\n",
        "    give=pd.DataFrame()\n",
        "    for features in X.keys():\n",
        "     s= extract_features(X,features)\n",
        "     if s.dtype !='O' and features!='Sex':    \n",
        "       s=s.fillna(s.mean())\n",
        "       s[s == -np.inf] =s.mean()\n",
        "       s[s == np.inf] =s.mean()\n",
        "       give[features]=s\n",
        "     elif features=='Sex':\n",
        "       s = s.map({'female': 1, 'male': 0})\n",
        "       give[features]=s\n",
        "    # YOUR CODE GOES HERE\n",
        "    return give\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5B83wUpeY7-"
      },
      "source": [
        "### 1.4.2 Entrene los modelos usando la nueva feature 'Sex'\n",
        "Usando las funciones ya implementadas anteriormente, haga pruebas con el nuevo Dataframe que contiene la columna 'sex'.\n",
        "\n",
        "\n",
        "**El modelo logístico debe superar 0.79 de precisión y bayes 0.78.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uy5bYn7hd1Qr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "87c832a0-2107-4184-a61e-11f2b91c936e"
      },
      "source": [
        "X_processed = process_data(X)\n",
        "logit = train_logit(X_processed, y)\n",
        "bayes = train_bayes(X_processed, y)\n",
        "\n",
        "print(logit.score(X_processed, y))\n",
        "print(bayes.score(X_processed, y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.797979797979798\n",
            "0.792368125701459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEhgFtrVkVYU"
      },
      "source": [
        "# 2 Métricas de Desempeño"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Rbb0vvab3p0"
      },
      "source": [
        "## 2.1 Defina una función que encuentre los Falsos Positivos y los Falsos Negativos de un modelo en un conjunto de prueba.\n",
        "\n",
        "Para este punto debe considerar como negativo _no supervivencia_ y como positivo _supervivencia_.\n",
        "\n",
        "Implemente la función `fpFn` que retorne una tupla de tipo (FP, FN) donde _FP_ son los falsos positivos y _FN_ los falsos negativos.\n",
        "\n",
        "**Peso del punto: 1.0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUSDDk2Hbfol"
      },
      "source": [
        "def fpFn(y_true, y_pred):\n",
        "    '''\n",
        "    y_true: lista con las etiquetas originales del dataset\n",
        "    y_pred: lista con las etiquetas predichas por un modelo\n",
        "    Returns:\n",
        "    (FP, FN) : Tupla donde FP son los falsos positivos, FN son los falsos negativos\n",
        "    '''\n",
        "    # YOUR CODE GOES HERE\n",
        "    FP=0\n",
        "    FN=0\n",
        "    for i in range(len(y_true)):\n",
        "      if y_true[i]!=y_pred[i]:\n",
        "        if y_true[i]==0:\n",
        "          FP+=1\n",
        "        else:\n",
        "          FN+=1\n",
        "    return (FP,FN)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IjnEMUFyc7Gq"
      },
      "source": [
        "## 2.2 (1.0) Defina una función que encuentre la Sensibilidad y Especificidad de un modelo en un conjunto de prueba.\n",
        "\n",
        "\n",
        "Recuerdas qué AIMA te contó una vez:\n",
        "\n",
        "'La sensibilidad caracteriza la capacidad de la prueba para detectar la enfermedad en sujetos enfermos. La especificidad caracteriza la capacidad de la prueba para detectar la ausencia de la enfermedad en sujetos sanos.'\n",
        "\n",
        "\n",
        "Implemente la función `seEs` que retorne una tupla de tipo (SE, ES) donde _SE_ es la sensibilidad y _ES_ es la especificidad.\n",
        "\n",
        "**Peso del punto: 1.0**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OVo9oJgcWnJ"
      },
      "source": [
        "def seEs(y_true, y_pred):\n",
        "    '''\n",
        "    Entrada:\n",
        "    y_true: lista con las etiquetas originales del dataset\n",
        "    y_pred: etiquetas predichas por un modelo\n",
        "    Salida:\n",
        "    (SE, ES) : SE es la Sensibilidad, ES la Especificidad\n",
        "    '''\n",
        "    # YOUR CODE GOES HERE\n",
        "    SE=0\n",
        "    ES=0\n",
        "    A=fpFn(y_true, y_pred)\n",
        "    FP=A[0]\n",
        "    FN=A[1]\n",
        "    for i in range(len(y_true)):\n",
        "      if y_pred[i]==0:\n",
        "        ES+=1\n",
        "      else:\n",
        "        SE+=1\n",
        "    ES=ES-FN\n",
        "    ES=ES/(ES+FP)\n",
        "    SE=SE-FP\n",
        "    SE=SE/(SE+FN) \n",
        "    return (SE,ES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmjR1FhPZ8CI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22313da3-d2e3-4eeb-f825-6cdbe760af6c"
      },
      "source": [
        "case = ([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0], [0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0])\n",
        "print(seEs(case[1],case[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(0.7631578947368421, 0.8126064735945485)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}